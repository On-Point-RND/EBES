optimizer:
  params:
    weight_decay: 0.0014003599472612257
    lr: 0.0024917518322710905
model:
  encoder:
    params:
      hidden_size: 46
      num_layers: 3
      dropout: 1.1013435378551212e-05
  preprocess:
    params:
      time_process: cat
      num_norm: false
      cat_emb_dim: 5
      num_emb_dim: 39
  aggregation:
    name: TakeLastHidden
unsupervised_loss:
  params:
    margin: 0.5725196538783559
unsupervised_trainer:
  total_iters: 0
