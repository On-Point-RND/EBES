optimizer:
  params:
    weight_decay: 4.033601435868991e-07
    lr: 0.0010969518346137463
model:
  encoder:
    params:
      hidden_size: 541
      num_layers: 2
      dropout: 1.706285357097099e-06
  preprocess:
    params:
      time_process: diff
      num_norm: false
      cat_emb_dim: 95
      num_emb_dim: 126
  aggregation:
    name: TakeLastHidden
unsupervised_loss:
  params:
    margin: 0.5026701056224367
unsupervised_trainer:
  total_iters: 100000
